import os
import numpy as np
from pathlib import Path
from PIL import Image
from tqdm import tqdm
import matplotlib
from matplotlib import pyplot as plt
from nilearn import datasets
from nilearn import plotting
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names
from torchvision import transforms
from sklearn.decomposition import IncrementalPCA
from sklearn.linear_model import LinearRegression
from scipy.stats import pearsonr as corr
import json
import statsmodels.api as sm
from Dataset import *

from torch.optim.lr_scheduler import StepLR, ExponentialLR

import torch.optim as optim
from transformers import CLIPProcessor, CLIPModel
import transformers

from torchviz import make_dot
import hiddenlayer as hl

class DumbNNModel(nn.Module):
    def __init__(self):
        super(DumbNNModel, self).__init__()
        
        # Shared backbone
        self.shared_layers = nn.Sequential(
            nn.Linear(32, 16),  # Expand feature space
            nn.LeakyReLU(),
            #nn.BatchNorm1d(1),
            #nn.Linear(32, 32),
            #nn.LeakyReLU(),
            #nn.Linear(32, 32),
            #nn.LeakyReLU(),
            #nn.Linear(32, 32),
            #nn.LeakyReLU(),
            #nn.Linear(32, 32),
            #nn.LeakyReLU(),
            #nn.Linear(32, 32),
            #nn.LeakyReLU(),
            #nn.Linear(32, 32),
            #nn.LeakyReLU(),
            #nn.Linear(32, 32),
            #nn.LeakyReLU(),
            #nn.Linear(16, 16),
            #nn.LeakyReLU(),
            #nn.BatchNorm1d(1),
            nn.Linear(16, 1)

 
 
        )
        
        # Output Head 1 (19004-dimensional)
        self.output_head_1 = nn.Sequential(
            nn.Linear(32, 20),
            #nn.InstanceNorm1d(256),
            #nn.BatchNorm1d(20),
            nn.LeakyReLU(),
            #nn.BatchNorm1d(20),
            nn.Linear(20, 20),
            nn.LeakyReLU(),
            nn.Linear(20,20),
            nn.LeakyReLU(),
            nn.Linear(20, 16),
            nn.LeakyReLU(),



            #nn.Linear(4096, 19004)  # Final output size
            nn.Linear(16, 1)
        )
       

        #self.output_head_2 = nn.Sequential(
        #    nn.Linear(512, 512),
        #    nn.InstanceNorm1d(512),
        #    nn.LeakyReLU(),
        #    nn.Linear(512, 512),
        #    nn.InstanceNorm1d(512),
        #    nn.LeakyReLU(),
        #    nn.Linear(512, 512),
        #    nn.InstanceNorm1d(512),
        #    nn.LeakyReLU(),
        #    nn.Linear(512, 512),
        #    nn.InstanceNorm1d(512),
        #    nn.LeakyReLU(),
        #    
        #    #nn.Linear(4096, 19004)  # Final output size
        #    nn.Linear(512, 20544)
        #)


        # Output Head 2 (20554-dimensional)
        #self.output_head_2 = nn.Sequential(
        #    nn.Linear(2048, 4096),
        #    nn.InstanceNorm1d(4096),
        #    nn.LeakyReLU(),
        #    nn.Linear(4096, 20544)  # Final output size
        #)

    def forward(self, x):
        #print(x.dtype)
        x=x.float()
        x.type(torch.DoubleTensor)
        print(x.shape)
        
        #out1 = self.shared_layers(x)  # Pass through shared layers
        #print(x.dtype)
        
        out1 = self.output_head_1(x)  # First output
        #out2 = self.output_head_2(x)  # Second output
        #print(out1.dtype)
        #print(out2.dtype)
        #return out1, out2  # Return both outputs
        return out1


def getArrays(ds):
    return ds['id'].to_numpy(), ds['caption'].to_numpy()

def get_order_fmri(idx, fmri):
    r = []
    for i in range(len(idx)):
        r.append(fmri[idx[i]])

    return r

def get_tokenized_data(tokenizer, captions, lh_fmri):
    tokenized_captions = []
    first_lh_fmri = []
    for i in range(len(captions)):
        tokenized_captions.append(tokenizer(captions[i], return_tensors='pt', padding='max_length', truncation=True,max_length=32)['input_ids'])
        first_lh_fmri.append(torch.tensor(float(lh_fmri[i][0])))

    return tokenized_captions, first_lh_fmri

def debug(cap, fmri):
    cp = cap.detach().cpu().numpy()

def main():
    LOC = Path('../algonauts23/dataset')

    SUBJ = 'subj01'
    PATH = LOC / 'algonauts_2023_challenge_data' / SUBJ / 'training_split' / 'training_fmri'
    MASK = LOC / 'algonauts_2023_challenge_data' / SUBJ / 'roi_masks'

    lh_path = PATH / "lh_training_fmri.npy"
    rh_path = PATH / 'rh_training_fmri.npy'
    lh_fmri = np.load(lh_path)
    rh_fmri = np.load(rh_path)

    lh_mask_path = MASK / 'lh.all-vertices_fsaverage_space.npy'
    rh_mask_path = MASK / 'rh.all-vertices_fsaverage_space.npy'
    lh_mask = np.load(lh_mask_path)
    rh_mask = np.load(rh_mask_path)

    #debug
    gradPrint = False
    debug = True

    print(lh_fmri)

    ds = getDataset(Path('..') /'algonauts23'/ 'dataset' / 'algonauts_2023_challenge_data','training', 'subj01')
    print(ds)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = DumbNNModel()

    loss_fn1 = nn.L1Loss()
    loss_fn2 = nn.L1Loss()
    
    
    
    #optimizer = optim.AdamW(model.parameters(), lr=0.5, maximize = False)
    #optimizer = optim.AdamW(model.parameters(), lr=0.05, maximize = False)
    optimizer = optim.AdamW(model.parameters(), lr=0.005, maximize = False)

    config = transformers.CLIPTextConfig()
    tokenizer = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")


    model.to(device)
    
    batch_size = 256
    
    #loading training data
    idx, captions = getArrays(ds)
    print(idx)
    tokCap, tok_lh_fmri = get_tokenized_data(tokenizer, captions, get_order_fmri(idx, lh_fmri))
    trainingData = TrainingData(tokCap, tok_lh_fmri)

    dataLoader = DataLoader(trainingData, batch_size = batch_size, shuffle = False)

    # Training loop
    num_epochs = 50
    
    scheduler = StepLR(optimizer, step_size=4, gamma=0.1) 
    #scheduler = ExponentialLR(optimizer, gamma=0.5) 

    print('training start')
    model.train()
    for epoch in range(num_epochs):
        total_loss = 0
        first = False
        for cap, lh_fmri_c in dataLoader:
            cap = cap.to(device)
            lh_fmri_c = lh_fmri_c.to(device)
            cap = cap.squeeze(1)

            print(cap.shape)
            

            output1 = model(cap)
            optimizer.zero_grad()
            loss1 = loss_fn1(output1, lh_fmri_c)
            #ot = output1.cpu().detach().numpy()[0][0][0]
            #ac = lh_fmri_c.cpu().detach().numpy()[0]
            loss = loss1
            loss.backward()
            optimizer.step()

            #print(output1)
            #print(lh_fmri_c)
            print()
            
            if debug:
                for i in range(len(lh_fmri_c)):
                    #ot = output1.cpu().detach().numpy()[i][0][0]
                    ot = output1.cpu().detach().numpy()[i]
                    ac = lh_fmri_c.cpu().detach().numpy()[i]
                    temp = output1.cpu().detach()
                    #print(output1)
                    #print(lh_fmri_c)
                    print(f'output: {ot}, actual: {ac:4}, loss: {loss:4}')

            print()
            #print(f'output: {ot:4}, actual: {ac:4}, loss: {loss:4}')
            #print(f'loss: {loss1:4}, output: {out}')
            #print(f'loss: {loss:4}')
            if first or debug:
                first = False
                #print(f'output: {ot:4}, actual: {ac:4}, loss: {loss:4}')
                if gradPrint == True:
                    for name, param in model.named_parameters():
                        if param.grad is not None:
                            print(f'Gradient for {name}: {param.grad}')



        scheduler.step()
        print()
        print(epoch)
        print()

    print("Training complete!")

    model.eval()
    ds = sortDataframe(ds)

    lh_pred = []
    rh_pred = []
    #for i in range(len(ds)):


    #    inputs = tokenizer(ds.iloc[i]['caption'], return_tensors='pt', padding='max_length', truncation=True,max_length=32)['input_ids'].to(device)
    #    #print(inputs)
    #    #print(len(inputs))
    #    #target1 = torch.Tensor(lh_fmri[ds.iloc[i]['id']]).to(device)
    #    temp1 = lh_fmri[ds.iloc[i]['id']][0]
    #    target1 = torch.tensor(float(temp1)).to(device)

    #    target2 = torch.Tensor(rh_fmri[ds.iloc[i]['id']]).to(device)
    #    

    #    target1 = target1.unsqueeze(0)
    #    target2 = target2.unsqueeze(0)
    #    optimizer.zero_grad()  # Reset gradients
    #    #output1, output2 = model(inputs)  # Forward pass
    #    output1 = model(inputs)

    #    #lh_pred.append(output1.to(torch.device('cpu')))
    #    #rh_pred.append(output2.to(torch.device('cpu')))

    #    lh_pred.append(output1.cpu().detach().numpy()[0].tolist())
    #    #print(output1.cpu().detach().numpy()[0])
    #    #rh_pred.append(output2.cpu().detach().numpy()[0].tolist())



    #    loss1 = loss_fn1(output1, target1)  # Compute loss for first output
    #    #loss2 = loss_fn2(output2, target2)  # Compute loss for second output

    #    #loss = loss1 + loss2  # Combine losses

    ##print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}, Loss1: {loss1:.4}, Loss2: {loss2:.4}")


    #np.save('lh_pred.npy', lh_pred)
    #np.save('rh_pred.npy', rh_pred)

    #inputs = tokenizer(ds.iloc[2]['caption'], return_tensors='pt', padding='max_length', truncation=True,max_length=512)['input_ids']


    #print(ds.iloc[2])
    #print(inputs)
    #print(inputs.shape)



if __name__ == '__main__':
    main()
